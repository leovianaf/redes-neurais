{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A0GQWDGtrpX"
      },
      "source": [
        "# Rede Neural de Base Radial (RBF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7W_VNPAkFcO"
      },
      "source": [
        "As redes RBF são redes de alimentação direta (feedforward) consistindo de três camadas:\n",
        "\n",
        "\n",
        "1.   **Camada de entrada**: propaga os estímulos\n",
        "2.   **Camada escondida**: Unidades de processamento localmente sintonizáveis, utilizando mapeamento não linear.\n",
        "3.   **Camada de saída**: Unidades de processamento lineares.\n",
        "\n",
        "\n",
        "****\n",
        "\n",
        "**O treinamento dessa rede ocorre de forma híbrida**, combinando aprendizagem não supervisionada (ANS) com a supervisionada(AS). Isso ocorre, pois em geral não se sabe quais saídas se desejam para a camada escondida. Sendo assim, a distribuição de trabalhos ocorre:\n",
        "*   **ANS**: Treina a camada escondida definindo seus parâmetros livres (centros, larguras dos campos receptivos e pesos).\n",
        "*   **AS**: Determina os valores dos pesos entre as camadas escondidas e de saída, considerando constantes os parâmetros já definidos.\n",
        "\n",
        "\n",
        "****\n",
        "\n",
        "**O aprendizado consiste em** determinar os valores para:\n",
        "*   centro das funções de base radial,\n",
        "*   largura das funções,\n",
        "*   pesos da camada de saída.\n",
        "\n",
        "\n",
        "Além disso, para cada neurônio da camada escondida, ele computa uma função de base radial.\n",
        "\n",
        "\n",
        "Os passos necessários são:\n",
        "1.   Utilizar um algoritmo ANS para encontrar os centros (protótipo para um cluster) das RBF;\n",
        "2.   Utilizar métodos heurísticos para determinar a largura (área de influência de um cluster) de cada função;\n",
        "3.   Utilizar um AS para determinar os pesos da camada de saída da rede."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOIor4J3PFBL"
      },
      "source": [
        "1ª Etapa: Inicialização dos grupos com K-Means"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHWuP3AXjvq1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d24c951f-3a62-49e1-9bc4-6e2b40d65b7c"
      },
      "source": [
        "!git clone https://github.com/valmirf/redes_neurais_pos.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'redes_neurais_pos'...\n",
            "remote: Enumerating objects: 120, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 120 (delta 11), reused 1 (delta 0), pack-reused 90 (from 1)\u001b[K\n",
            "Receiving objects: 100% (120/120), 16.66 MiB | 20.83 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ulVaA8RPSwo"
      },
      "source": [
        "Definição da função de base radial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeqYYe9hPY4v"
      },
      "source": [
        "# Função de base radial multiquadrática inversa\n",
        "def rbfMultiquadraticaInversa(x, c, s):\n",
        "    return 1 / np.sqrt((x - c)**2 + s**2)\n",
        "\n",
        "#função de base radial gaussiana\n",
        "def rbfGaussiana(x, c, s):\n",
        "    return np.exp(-1 / (2 * s**2) * (x-c)**2)\n",
        "\n",
        "#função de cálculo da largura do campo receptivo em que se repete o mesmo valor pra todos os neurônios\n",
        "def computeEqualStds(centers,k):\n",
        "  dist = [np.sqrt(np.sum((c1 - c2) ** 2)) for c1 in centers for c2 in centers]\n",
        "  dMax = np.max(dist)\n",
        "  stds = np.repeat(dMax / np.sqrt(2 * k), k)\n",
        "  return stds"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52oUNimoPuK3"
      },
      "source": [
        "2ª Etapa - Treinamento de uma Rede Neural"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGdrOhYfPzBu"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "class RBFNet(object):\n",
        "    \"\"\"Implementation of a Radial Basis Function Network\"\"\"\n",
        "\n",
        "    def __init__(self, k=3, attnumber=8, lr=0.01, epochs=100, rbf=rbfGaussiana, computeStds=computeEqualStds):\n",
        "        self.k = k  # grupos ou numero de neuronios na camada escondida\n",
        "        self.lr = lr # taxa de aprendizagem\n",
        "        self.epochs = epochs  # número de iterações\n",
        "        self.rbf = rbf # função de base radial\n",
        "        self.computeStds = computeStds  #função de cálculo da largura do campo receptivo\n",
        "\n",
        "        self.w = np.random.randn(self.k,attnumber)\n",
        "        self.b = np.random.randn(1)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.stds = []\n",
        "        #K-Means pra pegar os centros inicias\n",
        "        #1º parâmetro da rede RBF\n",
        "        kmeans = KMeans(\n",
        "            n_clusters=self.k, init='random',\n",
        "            n_init=10, max_iter=300).fit(X)\n",
        "        self.centers = kmeans.cluster_centers_\n",
        "        #print('centers: ', self.centers)\n",
        "\n",
        "        #Cálculo la dargura do campo receptivo\n",
        "        #2º parâmetro da rede RBF\n",
        "        self.stds = self.computeStds(self.centers,self.k)\n",
        "        # training\n",
        "        for epoch in range(self.epochs):\n",
        "            for i in range(X.shape[0]):\n",
        "                # forward pass\n",
        "                #calcula a saída de cada neurônio da função de base radial\n",
        "                phi = np.array([self.rbf(X[i], c, s) for c, s, in zip(self.centers, self.stds)])\n",
        "                #calcula somatório do produto da saída da função de base radial e os pesos\n",
        "                F = phi.T.dot(self.w)\n",
        "                F = np.sum(F) + self.b\n",
        "                #saída da rede\n",
        "                out = 0 if F < 0 else 1\n",
        "\n",
        "                #função de perda\n",
        "                loss = (y[i] - out).flatten() ** 2\n",
        "                #print('Loss: {0:.2f}'.format(loss[0]))\n",
        "\n",
        "                #cálculo do erro\n",
        "                error = (y[i] - out).flatten()\n",
        "                #atualização dos pesos\n",
        "                #3º Parâmetro da rede\n",
        "                self.w = self.w + self.lr * error * phi\n",
        "                self.b = self.b + self.lr * error\n",
        "\n",
        "    #calcula saída da rede RBF com a rede treinada\n",
        "    def predict(self, X):\n",
        "        y_pred = []\n",
        "        error = 0\n",
        "        for i in range(X.shape[0]):\n",
        "            a = np.array([self.rbf(X[i], c, s) for c, s, in zip(self.centers, self.stds)])\n",
        "            F = a.T.dot(self.w)\n",
        "            F = np.sum(F) + self.b\n",
        "            out = 0 if F < 0 else 1\n",
        "            y_pred.append(out)\n",
        "\n",
        "        return np.array(y_pred)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P75CdFJ4W7mU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "373dd0aa-a55d-4c00-e9c3-ee145cdfd48d"
      },
      "source": [
        "# Neste código vou utilizar o pandas, framework amplamente utilizado pra lidar com dados\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "#carrega a base de dados e retorna conjuntos de treinamento e teste\n",
        "def load_data():\n",
        "    url = 'redes_neurais_pos/RBF/diabetes.csv'\n",
        "    df = pd.read_csv(url)\n",
        "    #remove a ultima coluna (dados)\n",
        "    data = df[df.columns[:-1]]\n",
        "    #normaliza os dados\n",
        "    normalized_data = (data - data.min()) / (data.max() - data.min())\n",
        "    #retorna a última coluna (rótulos)\n",
        "    labels = df[df.columns[-1]]\n",
        "    #separa em conjunto de treinamento e teste com seus respectivos rótulos\n",
        "    X_train, X_test, y_train, y_test = train_test_split(normalized_data, labels, test_size=0.2, random_state=0)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "#chama função que carrega base de dados\n",
        "training_inputs, test_inputs, training_labels, test_labels = load_data()\n",
        "\n",
        "#transforma rótulos do conjunto de treinamento em numeros pra calculo do erro\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(training_labels.values)\n",
        "training_labels_transformed = le.transform(training_labels.values)\n",
        "\n",
        "#chama RBF\n",
        "rbfnet = RBFNet(lr=1e-2, attnumber=8, k=3, computeStds=computeEqualStds)\n",
        "rbfnet.fit(training_inputs.values, training_labels_transformed)\n",
        "\n",
        "#transforma rótulos do conjunto de teste em numeros pra calculo do erro\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(test_labels.values)\n",
        "test_labels_transformed = le.transform(test_labels.values)\n",
        "\n",
        "y_pred = rbfnet.predict(test_inputs.values) # Correção para usar dados de entrada para predição\n",
        "\n",
        "errorabs = abs(test_labels_transformed-y_pred)\n",
        "\n",
        "print('error: ', np.sum(errorabs)/len(test_labels_transformed))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error:  0.2662337662337662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLO2Gq4Jtso3"
      },
      "source": [
        "# Descrição Mini Projeto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOrl4i0areNo"
      },
      "source": [
        "Utilizando o código acima, modifique a última seção (Executando com Base de Dados) para que ele seja executado com a base de dados do arquivo diabetes.csv. Depois, modifique a função de base radial implementada (Gaussiana) para a Multiquadrática Inversa e calcule a taxa de erro.\n",
        "\n",
        "\n",
        "1- Calcular a quantidade de neurônios escondidos:\n",
        "\n",
        "a) 3\n",
        "\n",
        "b) 5\n",
        "\n",
        "c) 7\n",
        "\n",
        "d) 9\n",
        "\n",
        "Qual foi a melhor configuração? Avaliaria um outro valor?\n",
        "\n",
        "2- Utilizando a melhor configuração da questão anterior, calcular a taxa de erro usando uma das outras maneiras de retorno da largura do campo receptivo da função de base radial, em que cada neurônio possui sua própria largura.\n",
        "\n",
        "\n",
        "3- Calcular a taxa de erro combinando 2 funções de Base Radial e as duas maneiras de cálculo da largura do campo receptivo:\n",
        "\n",
        "a) Gaussiana\n",
        "\n",
        "b) Multiquadrática Inversa\n",
        "\n",
        "\n",
        "Qual foi a melhor configuração?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Questão\n",
        "\n",
        "Criei um loop para testar ambas as Redes com funções Radiais distintas e comparar os erros."
      ],
      "metadata": {
        "id": "uCQKcg4XjGT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neste código vou utilizar o pandas, framework amplamente utilizado pra lidar com dados\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "#carrega a base de dados e retorna conjuntos de treinamento e teste\n",
        "def load_data():\n",
        "    url = 'redes_neurais_pos/RBF/diabetes.csv'\n",
        "    df = pd.read_csv(url)\n",
        "    #remove a ultima coluna (dados)\n",
        "    data = df[df.columns[:-1]]\n",
        "    #normaliza os dados\n",
        "    normalized_data = (data - data.min()) / (data.max() - data.min())\n",
        "    #retorna a última coluna (rótulos)\n",
        "    labels = df[df.columns[-1]]\n",
        "    #separa em conjunto de treinamento e teste com seus respectivos rótulos\n",
        "    X_train, X_test, y_train, y_test = train_test_split(normalized_data, labels, test_size=0.2, random_state=0)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Carrega os dados\n",
        "training_inputs, test_inputs, training_labels, test_labels = load_data()\n",
        "\n",
        "# Transforma os rótulos em números\n",
        "le = preprocessing.LabelEncoder()\n",
        "training_labels_transformed = le.fit_transform(training_labels.values)\n",
        "test_labels_transformed = le.fit_transform(test_labels.values)\n",
        "\n",
        "# Função para testar diferentes configurações\n",
        "def evaluate_rbf(k_values, rbf_function):\n",
        "    errors = []\n",
        "    for k in k_values:\n",
        "        print(f\"Treinando RBF com k={k}, função {rbf_function.__name__}...\")\n",
        "        rbfnet = RBFNet(lr=1e-2, attnumber=8, k=k, rbf=rbf_function, computeStds=computeEqualStds)\n",
        "        rbfnet.fit(training_inputs.values, training_labels_transformed)\n",
        "        y_pred = rbfnet.predict(test_inputs.values)\n",
        "        errorabs = abs(test_labels_transformed - y_pred)\n",
        "        error_rate = np.sum(errorabs) / len(test_labels_transformed)\n",
        "        errors.append((k, error_rate))\n",
        "        print(f\"> Erro para k={k}: {error_rate:.4f}\")\n",
        "    return errors\n",
        "\n",
        "# Testa para os valores de k com as duas funções\n",
        "k_values = [3, 5, 7, 9]\n",
        "print(\"\\n--- Resultados para a Gaussiana ---\")\n",
        "errors_gaussiana = evaluate_rbf(k_values, rbfGaussiana)\n",
        "\n",
        "print(\"\\n--- Resultados para a Multiquadrática Inversa ---\")\n",
        "errors_multiquadratica = evaluate_rbf(k_values, rbfMultiquadraticaInversa)\n",
        "\n",
        "# Comparação\n",
        "print(\"\\n--- Comparação de Taxas de Erro ---\")\n",
        "print(\"Gaussiana:\", errors_gaussiana)\n",
        "print(\"Multiquadrática Inversa:\", errors_multiquadratica)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ9r8ywNjFwi",
        "outputId": "e01e8b60-5adf-41fd-fea6-50ac8456bf9e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Resultados para a Gaussiana ---\n",
            "Treinando RBF com k=3, função rbfGaussiana...\n",
            "> Erro para k=3: 0.2468\n",
            "Treinando RBF com k=5, função rbfGaussiana...\n",
            "> Erro para k=5: 0.2922\n",
            "Treinando RBF com k=7, função rbfGaussiana...\n",
            "> Erro para k=7: 0.3377\n",
            "Treinando RBF com k=9, função rbfGaussiana...\n",
            "> Erro para k=9: 0.2987\n",
            "\n",
            "--- Resultados para a Multiquadrática Inversa ---\n",
            "Treinando RBF com k=3, função rbfMultiquadraticaInversa...\n",
            "> Erro para k=3: 0.3247\n",
            "Treinando RBF com k=5, função rbfMultiquadraticaInversa...\n",
            "> Erro para k=5: 0.2143\n",
            "Treinando RBF com k=7, função rbfMultiquadraticaInversa...\n",
            "> Erro para k=7: 0.2338\n",
            "Treinando RBF com k=9, função rbfMultiquadraticaInversa...\n",
            "> Erro para k=9: 0.1948\n",
            "\n",
            "--- Comparação de Taxas de Erro ---\n",
            "Gaussiana: [(3, 0.24675324675324675), (5, 0.2922077922077922), (7, 0.33766233766233766), (9, 0.2987012987012987)]\n",
            "Multiquadrática Inversa: [(3, 0.3246753246753247), (5, 0.21428571428571427), (7, 0.23376623376623376), (9, 0.19480519480519481)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultados:\n",
        "\n",
        "--- Comparação de Taxas de Erro ---\n",
        "\n",
        "Gaussiana: [(3, 0.24675324675324675), (5, 0.2922077922077922), (7, 0.33766233766233766), (9, 0.2987012987012987)]\n",
        "\n",
        "Multiquadrática Inversa: [(3, 0.3246753246753247), (5, 0.21428571428571427), (7, 0.23376623376623376), (9, 0.19480519480519481)]\n",
        "\n",
        "**Melhor Configuração:**\n",
        "\n",
        "Para a **função Gaussiana**, a melhor configuração foi k = 3, pois apresentou o menor erro de 0.2468.\n",
        "\n",
        "Para a **função Multiquadrática Inversa**, a melhor configuração foi k = 9, com o menor erro de 0.1948.\n",
        "\n",
        "A configuração k = 9 para a função Multiquadrática Inversa parece ter dado o melhor desempenho entre todas as configurações. Entretanto, como k = 7 ainda teve um desempenho razoavelmente bom com erro = 0.2338, há uma chance de que valores intermediários (por exemplo, k = 8) possam produzir um bom equilíbrio entre o erro e a complexidade do modelo.\n",
        "\n",
        "Para a RBF Gaussiana, a configuração com k = 3 é a mais eficiente, mas vale a pena testar valores próximos, como k = 4 ou k = 2, para ver se o erro pode ser reduzido ainda mais ou se existe uma diminuição significativa com a mudança de k."
      ],
      "metadata": {
        "id": "_chdJiC3v704"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2º Questão\n",
        "\n",
        "Utilizando para função Multiquadrática Inversa k=9, realizei o teste com a função onde cada neurônio possui uma largura própria:"
      ],
      "metadata": {
        "id": "OV7KjUgp0eu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def computeIndividualStds(centers, *args):\n",
        "    stds = []\n",
        "    for i, ci in enumerate(centers):\n",
        "        # Calcula a menor distância entre o centro ci e os outros centros cj\n",
        "        min_dist = np.min([np.linalg.norm(ci - cj) for j, cj in enumerate(centers) if i != j])\n",
        "        # Define a largura como metade dessa menor distância\n",
        "        stds.append(min_dist / 2)\n",
        "    return np.array(stds)\n",
        "\n",
        "# Melhor configuração encontrada: k=9 para a Multiquadrática Inversa\n",
        "rbfnet = RBFNet(lr=1e-2, attnumber=8, k=9, rbf=rbfMultiquadraticaInversa, computeStds=computeIndividualStds)\n",
        "\n",
        "# Treinamento e teste\n",
        "rbfnet.fit(training_inputs.values, training_labels_transformed)\n",
        "y_pred = rbfnet.predict(test_inputs.values)\n",
        "\n",
        "# Cálculo da taxa de erro\n",
        "errorabs = abs(test_labels_transformed - y_pred)\n",
        "print('Erro com largura própria para melhor configuração: ', np.sum(errorabs) / len(test_labels_transformed))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOFqyR5K2HID",
        "outputId": "9c45fa44-5fb3-46a7-e0a0-59376eba56f5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Erro com largura própria para melhor configuração:  0.3051948051948052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultado:\n",
        "\n",
        "Melhor configuração: k=9, Multiquadrática Inversa\n",
        "\n",
        "O erro com largura própria pra cada neurônio foi: 0.3051948051948052"
      ],
      "metadata": {
        "id": "_H8Xl0AW4jyx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3º Questão\n",
        "\n",
        "Calcular a taxa de erro combinando 2 funções de Base Radial e as duas maneiras de cálculo da largura do campo receptivo:\n",
        "\n",
        "a) Gaussiana (Largura própria e Largura igual)\n",
        "\n",
        "b) Multiquadrática Inversa (Largura própria e Largura igual)"
      ],
      "metadata": {
        "id": "HPtGvo6E49Nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para treinar e avaliar a RBFNet com diferentes configurações\n",
        "def evaluate_rbf_combination(rbf_function, stds_function, X_train, y_train, X_test, y_test, k_values):\n",
        "    results = []\n",
        "    for k in k_values:\n",
        "        print(f\"Treinando RBF com k={k}, função {rbf_function.__name__}, largura {stds_function.__name__}...\")\n",
        "        rbfnet = RBFNet(lr=1e-2, attnumber=X_train.shape[1], k=k, rbf=rbf_function, computeStds=stds_function)\n",
        "        rbfnet.fit(X_train.values, y_train)\n",
        "        y_pred = rbfnet.predict(X_test.values)\n",
        "\n",
        "        # Calcula a taxa de erro\n",
        "        error_rate = np.sum(abs(y_test - y_pred)) / len(y_test)\n",
        "        results.append((k, error_rate))\n",
        "        print(f\"> Erro para k={k}: {error_rate:.4f}\")\n",
        "    print()\n",
        "    return results\n",
        "\n",
        "# Configurações\n",
        "k_values = [3, 5, 7, 9]  # Quantidades de neurônios escondidos a serem testadas\n",
        "\n",
        "# Avaliar combinações\n",
        "print(\"--- Avaliação de Combinações ---\")\n",
        "results_gaussian_equal = evaluate_rbf_combination(rbfGaussiana, computeEqualStds, training_inputs, training_labels_transformed, test_inputs, test_labels_transformed, k_values)\n",
        "results_gaussian_individual = evaluate_rbf_combination(rbfGaussiana, computeIndividualStds, training_inputs, training_labels_transformed, test_inputs, test_labels_transformed, k_values)\n",
        "results_multiquad_equal = evaluate_rbf_combination(rbfMultiquadraticaInversa, computeEqualStds, training_inputs, training_labels_transformed, test_inputs, test_labels_transformed, k_values)\n",
        "results_multiquad_individual = evaluate_rbf_combination(rbfMultiquadraticaInversa, computeIndividualStds, training_inputs, training_labels_transformed, test_inputs, test_labels_transformed, k_values)\n",
        "\n",
        "# Comparar resultados\n",
        "print(\"\\n--- Resultados Finais ---\")\n",
        "print(\"Gaussiana (Largura Igual):\", results_gaussian_equal)\n",
        "print(\"Gaussiana (Largura Própria):\", results_gaussian_individual)\n",
        "print(\"Multiquadrática Inversa (Largura Igual):\", results_multiquad_equal)\n",
        "print(\"Multiquadrática Inversa (Largura Própria):\", results_multiquad_individual)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDAhqI7_5LNQ",
        "outputId": "c2e85fbd-9ed3-4da3-fede-8c8fb6ac09fc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Avaliação de Combinações ---\n",
            "Treinando RBF com k=3, função rbfGaussiana, largura computeEqualStds...\n",
            "> Erro para k=3: 0.2338\n",
            "Treinando RBF com k=5, função rbfGaussiana, largura computeEqualStds...\n",
            "> Erro para k=5: 0.2857\n",
            "Treinando RBF com k=7, função rbfGaussiana, largura computeEqualStds...\n",
            "> Erro para k=7: 0.3247\n",
            "Treinando RBF com k=9, função rbfGaussiana, largura computeEqualStds...\n",
            "> Erro para k=9: 0.3247\n",
            "\n",
            "Treinando RBF com k=3, função rbfGaussiana, largura computeIndividualStds...\n",
            "> Erro para k=3: 0.2727\n",
            "Treinando RBF com k=5, função rbfGaussiana, largura computeIndividualStds...\n",
            "> Erro para k=5: 0.3377\n",
            "Treinando RBF com k=7, função rbfGaussiana, largura computeIndividualStds...\n",
            "> Erro para k=7: 0.3312\n",
            "Treinando RBF com k=9, função rbfGaussiana, largura computeIndividualStds...\n",
            "> Erro para k=9: 0.3182\n",
            "\n",
            "Treinando RBF com k=3, função rbfMultiquadraticaInversa, largura computeEqualStds...\n",
            "> Erro para k=3: 0.3117\n",
            "Treinando RBF com k=5, função rbfMultiquadraticaInversa, largura computeEqualStds...\n",
            "> Erro para k=5: 0.3377\n",
            "Treinando RBF com k=7, função rbfMultiquadraticaInversa, largura computeEqualStds...\n",
            "> Erro para k=7: 0.3442\n",
            "Treinando RBF com k=9, função rbfMultiquadraticaInversa, largura computeEqualStds...\n",
            "> Erro para k=9: 0.2013\n",
            "\n",
            "Treinando RBF com k=3, função rbfMultiquadraticaInversa, largura computeIndividualStds...\n",
            "> Erro para k=3: 0.2857\n",
            "Treinando RBF com k=5, função rbfMultiquadraticaInversa, largura computeIndividualStds...\n",
            "> Erro para k=5: 0.2792\n",
            "Treinando RBF com k=7, função rbfMultiquadraticaInversa, largura computeIndividualStds...\n",
            "> Erro para k=7: 0.3247\n",
            "Treinando RBF com k=9, função rbfMultiquadraticaInversa, largura computeIndividualStds...\n",
            "> Erro para k=9: 0.2078\n",
            "\n",
            "\n",
            "--- Resultados Finais ---\n",
            "Gaussiana (Largura Igual): [(3, 0.23376623376623376), (5, 0.2857142857142857), (7, 0.3246753246753247), (9, 0.3246753246753247)]\n",
            "Gaussiana (Largura Própria): [(3, 0.2727272727272727), (5, 0.33766233766233766), (7, 0.33116883116883117), (9, 0.3181818181818182)]\n",
            "Multiquadrática Inversa (Largura Igual): [(3, 0.3116883116883117), (5, 0.33766233766233766), (7, 0.34415584415584416), (9, 0.2012987012987013)]\n",
            "Multiquadrática Inversa (Largura Própria): [(3, 0.2857142857142857), (5, 0.2792207792207792), (7, 0.3246753246753247), (9, 0.2077922077922078)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultados:\n",
        "\n",
        "--- Resultados Finais ---\n",
        "\n",
        "**Gaussiana (Largura Igual)**: [(3, 0.23376623376623376), (5, 0.2857142857142857), (7, 0.3246753246753247), (9, 0.3246753246753247)]\n",
        "\n",
        "**Gaussiana (Largura Própria)**: [(3, 0.2727272727272727), (5, 0.33766233766233766), (7, 0.33116883116883117), (9, 0.3181818181818182)]\n",
        "\n",
        "**Multiquadrática Inversa (Largura Igual)**: [(3, 0.3116883116883117), (5, 0.33766233766233766), (7, 0.34415584415584416), (9, 0.2012987012987013)]\n",
        "\n",
        "**Multiquadrática Inversa (Largura Própria)**: [(3, 0.2857142857142857), (5, 0.2792207792207792), (7, 0.3246753246753247), (9, 0.2077922077922078)]\n",
        "\n",
        "**Melhor Configuração:**\n",
        "\n",
        "Para a **função Gaussiana**, a melhor configuração foi **k = 3** e a largura **igual para cada neurônio**, pois apresentou o menor erro de **0.2338**.\n",
        "\n",
        "Para a **função Multiquadrática Inversa**,  melhor configuração foi **k = 9** e a largura **igual para cada neurônio**, pois apresentou o menor erro de **0.2013**."
      ],
      "metadata": {
        "id": "EUu8kSZG6waI"
      }
    }
  ]
}